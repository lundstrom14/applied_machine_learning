{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NearestCentriodClassifier classifier, on all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, datasets\n",
    "import numpy as np\n",
    "import MNIST\n",
    "from gaussianNaiveBayesianClassifier import GaussianNaiveBayesianClassifier\n",
    "%config IPCompleter.greedy=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Digits dataset\n",
    "Load and split into 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  1257\n",
      "Number of test examples:  540\n",
      "Number of total examples: 1797\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "digits.data\n",
    "digits.data.shape\n",
    "\n",
    "num_split = int(0.7*len(digits.data))\n",
    "train_features = digits.data[:num_split]\n",
    "train_labels =  digits.target[:num_split]\n",
    "test_features = digits.data[num_split:]\n",
    "test_labels = digits.target[num_split:]\n",
    "\n",
    "print(\"Number of training examples: \",len(train_features))\n",
    "print(\"Number of test examples: \",len(test_features))\n",
    "print(\"Number of total examples:\", len(train_features)+len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64)\n",
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GaussianNaiveBayesianClassifier()\n",
    "gbc.fit(train_features, train_labels, 10)\n",
    "y_pred = gbc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn digits:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        53\n",
      "           1       0.72      0.74      0.73        53\n",
      "           2       0.98      0.85      0.91        53\n",
      "           3       0.93      0.74      0.82        53\n",
      "           4       0.98      0.91      0.95        57\n",
      "           5       0.87      0.95      0.91        56\n",
      "           6       0.96      0.98      0.97        54\n",
      "           7       0.78      0.83      0.80        54\n",
      "           8       0.64      0.71      0.67        52\n",
      "           9       0.73      0.82      0.77        55\n",
      "\n",
      "    accuracy                           0.85       540\n",
      "   macro avg       0.86      0.85      0.85       540\n",
      "weighted avg       0.86      0.85      0.85       540\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn digits:\n",
      "[[50  1  0  0  1  0  0  0  1  0]\n",
      " [ 1 39  0  0  0  0  0  0  3 10]\n",
      " [ 0  3 45  1  0  0  1  0  0  3]\n",
      " [ 0  0  0 39  0  2  0  2  9  1]\n",
      " [ 0  0  0  0 52  0  0  4  1  0]\n",
      " [ 0  1  0  0  0 53  1  0  1  0]\n",
      " [ 0  1  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  1  0  0  2  0 45  6  0]\n",
      " [ 0  8  0  1  0  1  0  2 37  3]\n",
      " [ 0  1  0  1  0  3  0  5  0 45]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report SKLearn digits:\\n%s\\n\"\n",
    "% (metrics.classification_report(test_labels, y_pred)))\n",
    "print(\"Confusion matrix SKLearn digits:\\n%s\" % metrics.confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Digits summarised dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and minify the data to dark, gray and light values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "flat_digits_data = digits.data.flatten()\n",
    "\n",
    "digits_data_summarised = np.zeros(len(flat_digits_data))\n",
    "for i,x in enumerate(flat_digits_data):\n",
    "    if x < 5:\n",
    "        digits_data_summarised[i] = 0 #dark\n",
    "    elif x > 10:\n",
    "        digits_data_summarised[i] = 2 #light\n",
    "    else:\n",
    "        digits_data_summarised[i] = 1 #gray\n",
    "        \n",
    "digits_data_summarised = digits_data_summarised.reshape(digits.data.shape)\n",
    "\n",
    "print(digits.data.shape)\n",
    "print(digits_data_summarised.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test set. 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  1257\n",
      "Number of test examples:  540\n",
      "Number of total examples: 1797\n"
     ]
    }
   ],
   "source": [
    "num_split = int(0.7*len(digits.data))\n",
    "train_features = digits_data_summarised[:num_split]\n",
    "train_labels =  digits.target[:num_split]\n",
    "test_features = digits_data_summarised[num_split:]\n",
    "test_labels = digits.target[num_split:]\n",
    "\n",
    "print(\"Number of training examples: \",len(train_features))\n",
    "print(\"Number of test examples: \",len(test_features))\n",
    "print(\"Number of total examples:\", len(train_features)+len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64)\n",
      "(1257,)\n",
      "[0. 0. 2. 2. 2. 1. 0. 0. 0. 1. 2. 1. 1. 2. 0. 0. 0. 0. 2. 0. 1. 2. 1. 0.\n",
      " 0. 0. 2. 2. 2. 2. 1. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 2. 1. 0.\n",
      " 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 2. 2. 2. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_features[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.fit(train_features, train_labels, 10)\n",
    "y_pred = gbc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn digits_summarised:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        53\n",
      "           1       0.86      0.68      0.76        53\n",
      "           2       0.98      0.92      0.95        53\n",
      "           3       0.93      0.75      0.83        53\n",
      "           4       0.95      0.93      0.94        57\n",
      "           5       0.92      0.86      0.89        56\n",
      "           6       0.98      0.91      0.94        54\n",
      "           7       0.84      0.89      0.86        54\n",
      "           8       0.63      0.88      0.74        52\n",
      "           9       0.70      0.82      0.76        55\n",
      "\n",
      "    accuracy                           0.86       540\n",
      "   macro avg       0.87      0.86      0.86       540\n",
      "weighted avg       0.87      0.86      0.86       540\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn digits_summarised:\n",
      "[[49  0  0  0  3  0  0  0  1  0]\n",
      " [ 0 36  0  0  0  1  0  0  4 12]\n",
      " [ 1  0 49  0  0  0  0  0  2  1]\n",
      " [ 0  1  0 40  0  0  0  3  9  0]\n",
      " [ 0  0  0  0 53  0  0  1  3  0]\n",
      " [ 0  1  1  0  0 48  1  0  2  3]\n",
      " [ 3  1  0  0  0  0 49  0  0  1]\n",
      " [ 0  0  0  0  0  1  0 48  5  0]\n",
      " [ 0  1  0  0  0  1  0  2 46  2]\n",
      " [ 0  2  0  3  0  1  0  3  1 45]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report SKLearn digits_summarised:\\n%s\\n\"\n",
    "% (metrics.classification_report(test_labels, y_pred)))\n",
    "print(\"Confusion matrix SKLearn digits_summarised:\\n%s\" % metrics.confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MNIST_light dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "mnist = MNIST.MNISTData('MNIST_Light/*/*.png')\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = mnist.get_data()  #70% train, 30% test\n",
    "\n",
    "print(train_features*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.fit(train_features, train_labels, 10)\n",
    "y_pred = gbc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       164\n",
      "           1       0.80      0.95      0.87       152\n",
      "           2       0.81      0.58      0.68       155\n",
      "           3       0.85      0.71      0.77       154\n",
      "           4       0.85      0.61      0.71       143\n",
      "           5       0.89      0.46      0.61       141\n",
      "           6       0.81      0.93      0.86       143\n",
      "           7       0.97      0.76      0.85       158\n",
      "           8       0.47      0.80      0.59       132\n",
      "           9       0.65      0.88      0.75       158\n",
      "\n",
      "    accuracy                           0.76      1500\n",
      "   macro avg       0.79      0.76      0.76      1500\n",
      "weighted avg       0.80      0.76      0.76      1500\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn:\n",
      "[[153   0   2   0   0   1   2   0   5   1]\n",
      " [  0 144   0   0   0   0   1   0   5   2]\n",
      " [  4   5  90   8   0   1  17   1  29   0]\n",
      " [  2   5  12 109   0   1   2   1  18   4]\n",
      " [  3   1   2   0  87   0   6   0   7  37]\n",
      " [ 10   5   1   8   3  65   1   0  46   2]\n",
      " [  3   3   0   0   0   2 133   0   2   0]\n",
      " [  0   2   2   0   7   0   0 120   1  26]\n",
      " [  1  14   2   1   0   3   3   0 105   3]\n",
      " [  5   0   0   2   5   0   0   2   5 139]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report SKLearn:\\n%s\\n\"\n",
    "% (metrics.classification_report(test_labels, y_pred)))\n",
    "print(\"Confusion matrix SKLearn:\\n%s\" % metrics.confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
