{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NearestCentriodClassifier classifier, on all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, datasets\n",
    "import numpy as np\n",
    "import MNIST\n",
    "from nearestCentroidClassifier import NearestCentriodClassifier\n",
    "%config IPCompleter.greedy=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Digits dataset\n",
    "Load and split into 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  1257\n",
      "Number of test examples:  540\n",
      "Number of total examples: 1797\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "digits.data\n",
    "digits.data.shape\n",
    "\n",
    "num_split = int(0.7*len(digits.data))\n",
    "train_features = digits.data[:num_split]\n",
    "train_labels =  digits.target[:num_split]\n",
    "test_features = digits.data[num_split:]\n",
    "test_labels = digits.target[num_split:]\n",
    "\n",
    "print(\"Number of training examples: \",len(train_features))\n",
    "print(\"Number of test examples: \",len(test_features))\n",
    "print(\"Number of total examples:\", len(train_features)+len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64)\n",
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc = GaussianNaiveBayesianClassifier()\n",
    "ncc.fit(train_features, train_labels, 10)\n",
    "y_pred = ncc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report SKLearn digits:\\n%s\\n\"\n",
    "% (metrics.classification_report(test_labels, y_pred)))\n",
    "print(\"Confusion matrix SKLearn digits:\\n%s\" % metrics.confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Digits summarised dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and minify the data to dark, gray and light values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "flat_digits_data = digits.data.flatten()\n",
    "\n",
    "digits_data_summarised = np.zeros(len(flat_digits_data))\n",
    "for i,x in enumerate(flat_digits_data):\n",
    "    if x < 5:\n",
    "        digits_data_summarised[i] = 0 #dark\n",
    "    elif x > 10:\n",
    "        digits_data_summarised[i] = 2 #light\n",
    "    else:\n",
    "        digits_data_summarised[i] = 1 #gray\n",
    "        \n",
    "digits_data_summarised = digits_data_summarised.reshape(digits.data.shape)\n",
    "\n",
    "print(digits.data.shape)\n",
    "print(digits_data_summarised.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test set. 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  1257\n",
      "Number of test examples:  540\n",
      "Number of total examples: 1797\n"
     ]
    }
   ],
   "source": [
    "num_split = int(0.7*len(digits.data))\n",
    "train_features = digits_data_summarised[:num_split]\n",
    "train_labels =  digits.target[:num_split]\n",
    "test_features = digits_data_summarised[num_split:]\n",
    "test_labels = digits.target[num_split:]\n",
    "\n",
    "print(\"Number of training examples: \",len(train_features))\n",
    "print(\"Number of test examples: \",len(test_features))\n",
    "print(\"Number of total examples:\", len(train_features)+len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64)\n",
      "(1257,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc.fit(train_features, train_labels, 10)\n",
    "y_pred = ncc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn digits_summarised:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        53\n",
      "           1       0.81      0.66      0.73        53\n",
      "           2       0.96      0.81      0.88        53\n",
      "           3       0.76      0.77      0.77        53\n",
      "           4       0.96      0.93      0.95        57\n",
      "           5       0.88      0.89      0.88        56\n",
      "           6       0.96      0.94      0.95        54\n",
      "           7       0.88      0.94      0.91        54\n",
      "           8       0.76      0.79      0.77        52\n",
      "           9       0.66      0.82      0.73        55\n",
      "\n",
      "    accuracy                           0.85       540\n",
      "   macro avg       0.86      0.85      0.85       540\n",
      "weighted avg       0.86      0.85      0.85       540\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn digits_summarised:\n",
      "[[51  0  0  0  1  1  0  0  0  0]\n",
      " [ 0 35  0  1  0  1  0  0  4 12]\n",
      " [ 1  1 43  7  0  0  0  0  0  1]\n",
      " [ 0  2  1 41  0  2  0  3  4  0]\n",
      " [ 1  0  0  0 53  0  0  0  3  0]\n",
      " [ 0  0  0  0  0 50  2  0  0  4]\n",
      " [ 0  3  0  0  0  0 51  0  0  0]\n",
      " [ 0  0  1  0  0  0  0 51  2  0]\n",
      " [ 0  1  0  0  1  1  0  2 41  6]\n",
      " [ 0  1  0  5  0  2  0  2  0 45]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report SKLearn digits_summarised:\\n%s\\n\"\n",
    "% (metrics.classification_report(test_labels, y_pred)))\n",
    "print(\"Confusion matrix SKLearn digits_summarised:\\n%s\" % metrics.confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MNIST_light dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST.MNISTData('MNIST_Light/*/*.png')\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = mnist.get_data()  #70% train, 30% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc.fit(train_features, train_labels, 10)\n",
    "y_pred = ncc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       164\n",
      "           1       0.71      0.97      0.82       152\n",
      "           2       0.84      0.73      0.78       155\n",
      "           3       0.74      0.76      0.75       154\n",
      "           4       0.75      0.76      0.75       143\n",
      "           5       0.72      0.69      0.70       141\n",
      "           6       0.90      0.86      0.88       143\n",
      "           7       0.95      0.80      0.87       158\n",
      "           8       0.79      0.72      0.75       132\n",
      "           9       0.76      0.80      0.78       158\n",
      "\n",
      "    accuracy                           0.80      1500\n",
      "   macro avg       0.81      0.80      0.80      1500\n",
      "weighted avg       0.81      0.80      0.80      1500\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn:\n",
      "[[150   0   2   0   0   6   3   1   2   0]\n",
      " [  0 148   0   0   0   2   0   0   2   0]\n",
      " [  0  15 113   8   2   3   3   1   8   2]\n",
      " [  1   5   8 117   1   7   1   2   8   4]\n",
      " [  1   4   2   0 108   0   3   0   1  24]\n",
      " [  3   9   0  24   4  97   2   0   1   1]\n",
      " [  3   6   2   0   4   5 123   0   0   0]\n",
      " [  1  14   2   0   6   1   0 127   1   6]\n",
      " [  3   6   4   8   0  12   1   0  95   3]\n",
      " [  3   0   1   1  19   2   1   3   2 126]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report SKLearn:\\n%s\\n\"\n",
    "% (metrics.classification_report(test_labels, y_pred)))\n",
    "print(\"Confusion matrix SKLearn:\\n%s\" % metrics.confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
